{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fdb69bfe",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import idx2numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "11b0eeb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = idx2numpy.convert_from_file(\"data/train-images-idx3-ubyte\")\n",
        "Y_train = idx2numpy.convert_from_file(\"data/train-labels-idx1-ubyte\")\n",
        "X_test = idx2numpy.convert_from_file(\"data/t10k-images-idx3-ubyte\")\n",
        "Y_test = idx2numpy.convert_from_file(\"data/t10k-labels-idx1-ubyte\")\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
        "# Normalize the data\n",
        "MinMaxScaler = preprocessing.MinMaxScaler()\n",
        "X_data_minmax = MinMaxScaler.fit_transform(X_train)\n",
        "X_test_data_minmax = MinMaxScaler.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5c3744c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def subsample_training(X, Y, M):\n",
        "    from numpy.random import default_rng\n",
        "    assert X.shape[0] == Y.shape[0]\n",
        "    assert M < X.shape[0]\n",
        "    rng = default_rng()\n",
        "    idxs = rng.choice(X.shape[0], size=M, replace=False)\n",
        "    return X.take(idxs, axis=0), Y.take(idxs, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1c9ecccc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_outliers(X, Y):\n",
        "    knn_clf=KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\")\n",
        "    knn_clf.fit(X, Y)\n",
        "    ypred=knn_clf.predict(X)\n",
        "    outliers = ypred != Y\n",
        "    # remove outliers\n",
        "    X, Y = X[~outliers], Y[~outliers]\n",
        "    return X, Y\n",
        "\n",
        "    pass\n",
        "def keep_useful(X, Y):\n",
        "    useful_X, useful_Y = [], []\n",
        "    labels_vis = set()\n",
        "    for x, y in zip(X, Y):\n",
        "        if y not in labels_vis:\n",
        "            useful_X.append(x)\n",
        "            useful_Y.append(y)\n",
        "            labels_vis.add(y)\n",
        "        else:\n",
        "            # Check if the value is misclassified\n",
        "            #import ipdb;ipdb.set_trace()\n",
        "            knn_clf=KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")\n",
        "            knn_clf.fit(useful_X, useful_Y)\n",
        "            ypred=knn_clf.predict([x])\n",
        "            if ypred[0] != y:\n",
        "                useful_X.append(x)\n",
        "                useful_Y.append(y)\n",
        "    return useful_X, useful_Y            \n",
        "\n",
        "\n",
        "def prototype_selection(X, Y):\n",
        "    orignal_sz = len(Y)\n",
        "    X, Y = remove_outliers(X, Y)\n",
        "    X, Y = keep_useful(X, Y)\n",
        "    print(f\"Factor by which the dataset is reduces is {orignal_sz/len(Y)} \")\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "27f56144",
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_values_and_calculate_accuracy_uniform_random(M):\n",
        "    # 1 NN, distance = Euclidian\n",
        "    knn_clf=KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")\n",
        "    X, Y = subsample_training(X_data_minmax, Y_train, M)\n",
        "    knn_clf.fit(X, Y)\n",
        "    ypred=knn_clf.predict(X_test_data_minmax)\n",
        "    result = confusion_matrix(Y_test, ypred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(result)\n",
        "    result1 = classification_report(Y_test, ypred)\n",
        "    print(\"Classification Report:\",)\n",
        "    print (result1)\n",
        "    result2 = accuracy_score(Y_test,ypred)\n",
        "    # print(type(result1))\n",
        "    print(\"Accuracy:\",result2)\n",
        "    return result2\n",
        "\n",
        "def predict_values_and_calculate_accuracy_prototype_subset(M):\n",
        "    # 1 NN, distance = Euclidian\n",
        "    knn_clf=KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")\n",
        "    X, Y = subsample_training(X_data_minmax, Y_train, M)\n",
        "    X, Y = prototype_selection(X, Y)\n",
        "\n",
        "    knn_clf.fit(X, Y)\n",
        "    ypred=knn_clf.predict(X_test_data_minmax)\n",
        "    # result = confusion_matrix(Y_test, ypred)\n",
        "    # print(\"Confusion Matrix:\")\n",
        "    # print(result)\n",
        "    #result1 = classification_report(Y_test, ypred)\n",
        "    #print(\"Classification Report:\",)\n",
        "    #print (result1)\n",
        "    result2 = accuracy_score(Y_test,ypred)\n",
        "    #print(\"Accuracy:\",result2)\n",
        "    return result2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "385f2f25",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_multiple_iterations(num_iterations, M):\n",
        "    accuracies_uniform = []\n",
        "    accuracies_prototype_selection = []\n",
        "    for i in range(num_iterations):\n",
        "        accuracies_uniform.append(predict_values_and_calculate_accuracy_uniform_random(M))\n",
        "        accuracies_prototype_selection.append(predict_values_and_calculate_accuracy_prototype_subset(M))\n",
        "    print(accuracies_uniform)    \n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    #plt.ylim(-0.2, 2)\n",
        "    labels = [f\"{M}_{i}\" for i in range(num_iterations)]\n",
        "\n",
        "    x = np.arange(len(labels))  # the label locations\n",
        "    width = 0.35  # the width of the bars\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    rects1 = ax.bar(x - width/2, accuracies_uniform, width, label='Men')\n",
        "    rects2 = ax.bar(x + width/2, accuracies_prototype_selection, width, label='Women')\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylim(-0.2, 2)\n",
        "    ax.set_ylabel('Scores')\n",
        "    ax.set_title('Scores by group and gender')\n",
        "    #ax.set_xticks(x, labels)\n",
        "    ax.legend()\n",
        "\n",
        "    ax.bar_label(rects1, padding=3)\n",
        "    ax.bar_label(rects2, padding=3)\n",
        "\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.show()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a47287c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[ 944    1    0    2    0   12   18    1    1    1]\n",
            " [   0 1128    2    1    0    0    2    0    0    2]\n",
            " [  21   36  847   26   16    6    9   51   15    5]\n",
            " [   6    8    8  900    0   35    2   16   21   14]\n",
            " [   2   27    0    0  823    1   12   13    2  102]\n",
            " [  11   15    0   57    3  731   23    6   15   31]\n",
            " [  13   12    1    1    6   11  908    0    3    3]\n",
            " [   0   44    1    3   11    1    0  922    2   44]\n",
            " [  13   19   10   70   13   33    9   15  749   43]\n",
            " [   8   16    1    7   43    6    1   40    7  880]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94       980\n",
            "           1       0.86      0.99      0.92      1135\n",
            "           2       0.97      0.82      0.89      1032\n",
            "           3       0.84      0.89      0.87      1010\n",
            "           4       0.90      0.84      0.87       982\n",
            "           5       0.87      0.82      0.85       892\n",
            "           6       0.92      0.95      0.94       958\n",
            "           7       0.87      0.90      0.88      1028\n",
            "           8       0.92      0.77      0.84       974\n",
            "           9       0.78      0.87      0.82      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.89      0.88      0.88     10000\n",
            "weighted avg       0.89      0.88      0.88     10000\n",
            "\n",
            "Accuracy: 0.8832\n",
            "Factor by which the dataset is reduces is 5.813953488372093 \n",
            "Confusion Matrix:\n",
            "[[ 937    1    1    4    1   13   18    2    1    2]\n",
            " [   0 1128    2    2    0    1    1    0    1    0]\n",
            " [  20   36  874   12   10    0   10   42   25    3]\n",
            " [   3    5   10  881    2   61    1   12   25   10]\n",
            " [   4   15    4    0  858    0    8    6    2   85]\n",
            " [   9    9    1   47    7  766   15   11   14   13]\n",
            " [  26   10    0    0    7    2  910    2    0    1]\n",
            " [   0   39    4    0    9    0    0  936    0   40]\n",
            " [   8    7    6   48   12   55   13   13  793   19]\n",
            " [  10   10    4    3   44    5    1   63    9  860]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.90      0.99      0.94      1135\n",
            "           2       0.96      0.85      0.90      1032\n",
            "           3       0.88      0.87      0.88      1010\n",
            "           4       0.90      0.87      0.89       982\n",
            "           5       0.85      0.86      0.85       892\n",
            "           6       0.93      0.95      0.94       958\n",
            "           7       0.86      0.91      0.89      1028\n",
            "           8       0.91      0.81      0.86       974\n",
            "           9       0.83      0.85      0.84      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.90      0.89      0.89     10000\n",
            "weighted avg       0.90      0.89      0.89     10000\n",
            "\n",
            "Accuracy: 0.8943\n",
            "Factor by which the dataset is reduces is 5.46448087431694 \n",
            "Confusion Matrix:\n",
            "[[ 955    2    2    2    0    3   11    3    0    2]\n",
            " [   0 1126    3    1    0    1    3    0    0    1]\n",
            " [  26   44  858   16    7    8    4   51   13    5]\n",
            " [   3    7    7  886    1   58    3   19   15   11]\n",
            " [   3   22    1    2  834    3   11    7    0   99]\n",
            " [  15    8    1   63    7  744   20    3   15   16]\n",
            " [  17    6    2    0    7   13  910    2    0    1]\n",
            " [   0   35    3    1   15    3    0  912    3   56]\n",
            " [  12   12   14   34   11   30   17   12  785   47]\n",
            " [   6    6    3    6   35    4    3   42    2  902]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95       980\n",
            "           1       0.89      0.99      0.94      1135\n",
            "           2       0.96      0.83      0.89      1032\n",
            "           3       0.88      0.88      0.88      1010\n",
            "           4       0.91      0.85      0.88       982\n",
            "           5       0.86      0.83      0.85       892\n",
            "           6       0.93      0.95      0.94       958\n",
            "           7       0.87      0.89      0.88      1028\n",
            "           8       0.94      0.81      0.87       974\n",
            "           9       0.79      0.89      0.84      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "Accuracy: 0.8912\n",
            "Factor by which the dataset is reduces is 5.376344086021505 \n",
            "Confusion Matrix:\n",
            "[[ 949    1    3    2    0    9   11    2    2    1]\n",
            " [   0 1126    1    1    1    0    4    0    1    1]\n",
            " [  14   53  850   28    4    2   14   30   32    5]\n",
            " [   5    7    3  893    0   49    3   11   18   21]\n",
            " [   6   15    2    0  793    3   12   18    0  133]\n",
            " [   9   13    3   37   11  751   21   14   18   15]\n",
            " [  14    4    1    0    4   21  913    1    0    0]\n",
            " [   1   40    0    4   16    0    0  927    0   40]\n",
            " [   9   10   10   55   16   52   17    7  766   32]\n",
            " [   3    8    4    8   51    8    3   43    5  876]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95       980\n",
            "           1       0.88      0.99      0.93      1135\n",
            "           2       0.97      0.82      0.89      1032\n",
            "           3       0.87      0.88      0.88      1010\n",
            "           4       0.89      0.81      0.84       982\n",
            "           5       0.84      0.84      0.84       892\n",
            "           6       0.91      0.95      0.93       958\n",
            "           7       0.88      0.90      0.89      1028\n",
            "           8       0.91      0.79      0.84       974\n",
            "           9       0.78      0.87      0.82      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.89      0.88      0.88     10000\n",
            "weighted avg       0.89      0.88      0.88     10000\n",
            "\n",
            "Accuracy: 0.8844\n",
            "Factor by which the dataset is reduces is 5.376344086021505 \n",
            "Confusion Matrix:\n",
            "[[ 957    1    1    1    1    9    6    1    3    0]\n",
            " [   0 1127    1    1    2    0    3    1    0    0]\n",
            " [  28   41  878   18    3    3    7   30   19    5]\n",
            " [   3    7   20  879    0   55    1    6   33    6]\n",
            " [   1   16    2    0  834    0   14   19    1   95]\n",
            " [   8    7    1   64    3  739   16    5   18   31]\n",
            " [  21   11    0    0   12   12  901    0    0    1]\n",
            " [   0   33    6    7    8    0    0  926    3   45]\n",
            " [  16   12   18   51   11   49   11   13  766   27]\n",
            " [   4   12    4    7   42    9    2   50    7  872]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95       980\n",
            "           1       0.89      0.99      0.94      1135\n",
            "           2       0.94      0.85      0.89      1032\n",
            "           3       0.86      0.87      0.86      1010\n",
            "           4       0.91      0.85      0.88       982\n",
            "           5       0.84      0.83      0.84       892\n",
            "           6       0.94      0.94      0.94       958\n",
            "           7       0.88      0.90      0.89      1028\n",
            "           8       0.90      0.79      0.84       974\n",
            "           9       0.81      0.86      0.83      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "Accuracy: 0.8879\n",
            "Factor by which the dataset is reduces is 5.882352941176471 \n",
            "[0.8832, 0.8943, 0.8912, 0.8844, 0.8879]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_multiple_iterations(5, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "119a9ec1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "8856b185",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       980\n",
            "           1       0.97      0.99      0.98      1135\n",
            "           2       0.98      0.96      0.97      1032\n",
            "           3       0.96      0.96      0.96      1010\n",
            "           4       0.97      0.96      0.97       982\n",
            "           5       0.95      0.96      0.96       892\n",
            "           6       0.98      0.99      0.98       958\n",
            "           7       0.96      0.96      0.96      1028\n",
            "           8       0.98      0.94      0.96       974\n",
            "           9       0.96      0.96      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n",
            "Accuracy: 0.9691\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "2b8db25f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "1e266ec4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "c6c378c8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cded3409",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3bb7d99",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "aee5b589",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[3, 4, 5, 6],\n",
              "        [5, 6, 7, 8]],\n",
              "\n",
              "       [[4, 4, 5, 6],\n",
              "        [5, 6, 7, 9]]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]],\n",
        "              [[3, 4, 5, 6], [5, 6, 7, 8]],\n",
        "              [[4, 4, 5, 6], [5, 6, 7, 9]]])\n",
        "#x[np.array([0, 1, 1], dtype=\"bool\")]\n",
        "x.take([1,2], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e96f1aae",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "HAP_simulation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
